<center><b>Security and Privacy in Machine Learning</b></center>
<center>Sharif University of Technology, Iran</center>
<center>CE Department</center>
<center>Fall 2025</center>


&nbsp;&nbsp;&nbsp;

_Welcome_ to the public page for the course on Security and Privacy in Machine Learning (SPML). The main objectives of the course are to introduce students to the principles of security and privacy in machine learning. The students become familiar with the vulnerabilities of machine learning in the training and inference phases and the methods to improve the robustness and privacy of machine learning models.



**Course Logistics**

   * **Time:**  Saturday &  Monday: 10:30 – 12:00
   * **Location:** Room 103 & [vc.sharif.edu/ch/amsadeghzadeh](https://vc.sharif.edu/ch/amsadeghzadeh)
   * **Contact:** Announcements and all course-related questions will happen on the [Quera](https://quera.org/course/add_to_course/course/23877/) forum. 
    * All official announcements and communication will happen over [Telegram](https://t.me/SPML2025) channel.
     * For external enquiries, emergencies, or personal matters that you don't wish to put in a private post, you can email me at sadeghzadeh_at_sharif_dot_edu



**Instructor**

&nbsp;&nbsp;&nbsp;_Amir Mahdi Sadeghzadeh_  
&nbsp;&nbsp;&nbsp;Office: CE-704
&nbsp;&nbsp;&nbsp;Lab: CE-502
&nbsp;&nbsp;&nbsp;Office Hours: By appointment (through Email)  
&nbsp;&nbsp;&nbsp;Email: [amsadeghzadeh_at_gmail.com](mailto:amsadeghzadeh@gmail.com)  
&nbsp;&nbsp;&nbsp;URL: [amsadeghzadeh.github.io](https://amsadeghzadeh.github.io)  



**Course Staff**

* _Arian Komaei Koma_ (Head Course Assistant) - Email: [ariankomaei_at_gmail.com](mailto:ariankomaei@gmail.com)
* _Alireza Faraj Tabrizi_ (Head Course Assistant) - Email: [Alireza15farajtabrizi_at_gmail.com](mailto:Alireza15farajtabrizi@gmail.com)
* _Amir Ezzati_ (Head Course Assistant) - Email: [iamirezzati_at_gmail.com](mailto:iamirezzati@gmail.com)
* _Firoozeh Abrishami_ (Course Assistant) - Email: [f.abrishami110_at_gmail.com](mailto:f.abrishami110@gmail.com)
* _Ramtin moslemi_ (Course Assistant) - Email: [ramtin4moslemi_at_gmail.com](mailto:ramtin4moslemi@gmail.com)
* _Erfan Sobhaei_ (Course Assistant) - Email: [E.sobhaei_at_gmail.com](mailto:E.sobhaei@gmail.com)





**Course Pages** 

* [spml2025.github.io](spml2025.github.io) -> Course information, syllabus, and materials.
* [Course Telgram Channel](https://t.me/SPML2025)
* [Quera](https://quera.org/course/add_to_course/course/23877/) (Get the password from course staff) -> Announcements, assignments, and all course-related questions.
* [Course Telegram Group](https://t.me/kp_gfe) -> Contact the Head Teaching Assistant for student confirmation and group inclusion.


**Main References** 

The main references for the course are many research papers in top-tier conferences and journals in computer security (SP, CCS, Usenix Security, EuroSP) and machine learning (NeurIPS, ICLR, ICML, CVPR, ECCV). Three following books are used for presenting background topics in machine learning and deep learning in
the first part of the course.

-   [Christopher M. Bishop, *Pattern Recognition and Machine Learning*,
    Springer,
    2006.](http://users.isr.ist.utl.pt/~wurmd/Livros/school/Bishop%20-%20Pattern%20Recognition%20And%20Machine%20Learning%20-%20Springer%20%202006.pdf)

-   [Ian Goodfellow, *Deep Learning*, MIT Press,
    2016.](https://www.deeplearningbook.org/)

-   [Aston Zhang, Dive into Deep Learning, 2020 ](http://d2l.ai/)



**Grading Policy**

- Assignments (30%) 

- 4 Quizzes (10%)

- Presentation (10%)

- Mid-term (20%)

- Final (30%).



**Course Policy**

-   This course considers topics involving personal and public privacy
    and security. As part of this investigation we will cover
    technologies whose abuse may infringe on the rights of others. As an
    instructor, I rely on the ethical use of these technologies.
    Unethical use may include circumvention of existing security or
    privacy measurements for any purpose, or the dissemination,
    promotion, or exploitation of vulnerabilities of these services.
    Exceptions to these guidelines may occur in the process of reporting
    vulnerabilities through public and authoritative channels. Any
    activity outside the letter or spirit of these guidelines will be
    reported to the proper authorities and may result in dismissal from
    the class. When in doubt, please contact the instructor for advice. **Do not**
    undertake any action which could be perceived as technology misuse
    anywhere and/or under any circumstances unless you have received
    explicit permission from Dr. Sadeghzadeh.



**Academic Honesty** 

[Sharif CE Department Honor Code](https://docs.ce.sharif.edu/rules/ethics) (please read it carefully!)



**Homework Submission**

Submit your answers in .pdf or .zip file in course page on Quera website, with the following format:
HW[HW#]-[FamilyName]-[std#] (For example HW3-Hoseini-401234567)

###  Homework Policy

**Important:**
- All **theory homework must be handwritten.**  
- **Do not submit** LaTeX or Word-formatted documents for theory assignments — these **will not be accepted.**  
- If any part of your homework is **detected to be written by AI**, you will **receive no score** for that assignment.  
- You may use AI tools for assistance (e.g., brainstorming ideas, clarifying concepts, or debugging), but **you must not include AI-generated text directly in your submission**. All submitted work should be written in your own words and understanding.




**Late Policy**

* All students have 15 free late days for the assignments.
* You may use up to 4 late days per assignment with no penalty.
* Once you have exhausted your free late days, we will deduct a late penalty of 20% per additional late day.


&nbsp;&nbsp;&nbsp;

&nbsp;&nbsp;&nbsp;


| # | Date  | Topic | Content| Lecture | Reading| HWs | Quiz
|---|-------|-------------------|--------------------------------------------|---------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|------|------
| 1 | 7/19 | Course Intro.     | The scope and contents of the course       | [Lec1](https://github.com/spml2025/spml2025.github.io/raw/main/Lectures/Lec1.pdf)    | [Towards the Science of Security and Privacy in Machine Learning](https://arxiv.org/abs/1611.03814)                 |          |                                                                                                                                                 |     |
| 2 | 7/21 | Deep Learning Review     | ML Intro., Perceptron, Logistic regression, GD, Regularization       | [Lec2](https://github.com/spml2025/spml2025.github.io/raw/main/Lectures/Lec2.pdf)    | [Pattern Recognition and Machine Learning Ch.1 & Ch.4](http://users.isr.ist.utl.pt/~wurmd/Livros/school/Bishop\%20-\%20Pattern\%20Recognition\%20And\%20Machine\%20Learning\%20-\%20Springer\%20\%202006.pdf) <br> [Deep Learning Ch.5 & Ch.6](https://www.deeplearningbook.org/)                                                                                                                                                                          |     |
| 3 | 7/26 | Adversarial Examples     | Properties of neural networks, Adversarial Example (L-BFGS), Type of Adversarial Attacks            | [Lec3](https://github.com/spml2025/spml2025.github.io/raw/main/Lectures/Lec3.pdf)    |  [Intriguing Properties of Neural Networks](https://arxiv.org/abs/1312.6199)                 |     |
| 4 | 7/28 | Adversarial Examples    | Fast Gradient Sign Method(FGSM) Attack, L_P Norms         | [Lec4](https://github.com/spml2025/spml2025.github.io/raw/main/Lectures/Lec4.pdf)    | [Explaining and Harnessing Adversarial Examples](https://arxiv.org/abs/1412.6572)     |                                                                               |     |
| 5 | 8/3 | Adversarial Examples             |  C&W Attack                      | [Lec5](https://github.com/spml2025/spml2025.github.io/raw/main/Lectures/Lec5.pdf)   | [Towards Evaluating the Robustness of Neural Networks](https://arxiv.org/abs/1608.04644) |     | 
| 6 | 8/5  | Adversarial Examples             |   Projected Gradient Descent, Universal Adversarial Perturbations, Adversarial Patch                           | [Lec6](https://github.com/spml2025/spml2025.github.io/raw/main/Lectures/Lec6.pdf)   |      [Universal Adversarial Perturbations](https://arxiv.org/abs/1610.08401) <br> [Adversarial Patch](https://arxiv.org/abs/1712.09665)              |      |  Quiz1
| 7 | 8/10 | Adversarial Examples             |Obfuscated Gradients, Adversarial Training, TRADES                        | [Lec7](https://github.com/spml2025/spml2025.github.io/raw/main/Lectures/Lec7.pdf)   |   [Theoretically Principled Trade-off between Robustness and Accuracy](https://arxiv.org/abs/1901.08573)  <br>   [Mitigating Adversarial Effects Through Randomization](https://arxiv.org/abs/1711.01991) <br> [Distillation as a Defense to Adversarial Perturbations against Deep Neural Networks](https://arxiv.org/abs/1511.04508)|    | 
| 8 | 8/12 | Adversarial Examples              | Certifiable Robustness, Randomized Smoothing                       | [Lec8](https://github.com/spml2025/spml2025.github.io/raw/main/Lectures/Lec8.pdf)   |[Certified Adversarial Robustness via Randomized Smoothing](https://arxiv.org/abs/1902.02918)|    |
| 9 | 8/17 | Black Box AE             |                       | [Lec9](https://github.com/spml2025/spml2025.github.io/raw/main/Lectures/Lec9.pdf)   |                                                                   |    |
| 10 | 8/19 | Black Box AE             |                       | [Lec10](https://github.com/spml2025/spml2025.github.io/raw/main/Lectures/Lec10.pdf)   |                                                                   |    |
| 11 | 8/24 |  Poisoning             |                       | [Lec11](https://github.com/spml2025/spml2025.github.io/raw/main/Lectures/Lec9.pdf)   |                                                                   |    |
| 12 | 8/26 | Poisoning             |                       | [Lec12](https://github.com/spml2025/spml2025.github.io/raw/main/Lectures/Lec9.pdf)   |                                                                   |    | Quiz2
| 13 | 9/1 | Model extraction            |                       | [Lec13](https://github.com/spml2025/spml2025.github.io/raw/main/Lectures/Lec9.pdf)   |                                                                   |    |
| Exam | 9/6 | Midterm             |                       |   |                                                                   |    |
| 14 | 9/8 | MIA             |                       | [Lec14](https://github.com/spml2025/spml2025.github.io/raw/main/Lectures/Lec9.pdf)   |                                                                   |    |
| 15 | 9/10 | MIA in generative models             |                       | [Lec15](https://github.com/spml2025/spml2025.github.io/raw/main/Lectures/Lec9.pdf)   |                                                                   |    |
| 16 | 9/15 | DP             |                       | [Lec16](https://github.com/spml2025/spml2025.github.io/raw/main/Lectures/Lec9.pdf)   |                                                                   |    |
| 17 | 9/17 | DP             |                       | [Lec17](https://github.com/spml2025/spml2025.github.io/raw/main/Lectures/Lec9.pdf)   |                                                                   |    |
| 18 | 9/22 | DP             |                       | [Lec18](https://github.com/spml2025/spml2025.github.io/raw/main/Lectures/Lec9.pdf)   |                                                                   |    | Quiz3
| 19 | 9/24 | DP             |                       | [Lec19](https://github.com/spml2025/spml2025.github.io/raw/main/Lectures/Lec9.pdf)   |                                                                   |    |
| 20 | 9/29 | Intro to LLM and challenges              |                       | [Lec20](https://github.com/spml2025/spml2025.github.io/raw/main/Lectures/Lec9.pdf)   |                                                                   |    |
| 21 | 10/1 | Hallucination             |                       | [Lec21](https://github.com/spml2025/spml2025.github.io/raw/main/Lectures/Lec9.pdf)   |                                                                   |    |
| 22 | 10/6 | Alignment(RLHF-DPO)             |                       | [Lec22](https://github.com/spml2025/spml2025.github.io/raw/main/Lectures/Lec9.pdf)   |                                                                   |    |
| 23 | 10/8 | Jailbreak of llm            |                       | [Lec23](https://github.com/spml2025/spml2025.github.io/raw/main/Lectures/Lec9.pdf)   |                                                                   |    |
| 24 | 10/15 | Jailbreak of vlm           |                       | [Lec24](https://github.com/spml2025/spml2025.github.io/raw/main/Lectures/Lec9.pdf)   |                                                                   |    | Quiz4
| 25 | 10/20 | -             |                       | [Lec25](https://github.com/spml2025/spml2025.github.io/raw/main/Lectures/Lec9.pdf)   |                                                                   |    |
| 26 | 10/22 | -             |                       | [Lec26](https://github.com/spml2025/spml2025.github.io/raw/main/Lectures/Lec9.pdf)   |                                                                   |    |
| Exam | 11/4 | Final             |                       |    |                                                                   |    |
