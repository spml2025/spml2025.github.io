<center><b>Security and Privacy in Machine Learning</b></center>
<center>Sharif University of Technology, Iran</center>
<center>CE Department</center>
<center>Fall 2025</center>


&nbsp;&nbsp;&nbsp;


_Welcome_ to the public page for the course on Security and Privacy in Machine Learning (SPML). The main objectives of the course are to introduce students to the principles of security and privacy in machine learning. The students become familiar with the vulnerabilities of machine learning in the training and inference phases and the methods to improve the robustness and privacy of machine learning models.



**Course Logistics**

   * **Time:** -
   * **Location:** - & [vc.sharif.edu/ch/amsadeghzadeh](https://vc.sharif.edu/ch/amsadeghzadeh)
   * **Contact:** Announcements and all course-related questions will happen on the [Quera](https://quera.org/course/add_to_course/course/18760/) forum. 
     * All official announcements and communication will happen over Quera.
     * For external enquiries, emergencies, or personal matters that you don't wish to put in a private post, you can email me at sadeghzadeh_at_sharif_dot_edu



**Instructor**

&nbsp;&nbsp;&nbsp;_Amir Mahdi Sadeghzadeh_  
&nbsp;&nbsp;&nbsp;Office: CE-704
&nbsp;&nbsp;&nbsp;Lab: CE-502
&nbsp;&nbsp;&nbsp;Office Hours: By appointment (through Email)  
&nbsp;&nbsp;&nbsp;Email: [amsadeghzadeh_at_gmail.com](mailto:amsadeghzadeh@gmail.com)  
&nbsp;&nbsp;&nbsp;URL: [amsadeghzadeh.github.io](https://amsadeghzadeh.github.io)  



**Course Staff**

* _Arian Komaei Koma_ (Head Course Assistant) - Email: [ariankomaei_at_gmail.com](mailto:ariankomaei@gmail.com)
* _Alireza Faraj Tabrizi_ (Head Course Assistant) - Email: [Alirezafarajtabrizi15_at_gmail.com](mailto:Alirezafarajtabrizi15@gmail.com)






**Course Pages** 

* [spml2025.github.io](spml2025.github.io) -> Course information, syllabus, and materials.
* [Quera](https://quera.org/course/add_to_course/course/18760/) (Get the password from course staff) -> Announcements, assignments, and all course-related questions.



**Main References** 

The main references for the course are many research papers in top-tier conferences and journals in computer security (SP, CCS, Usenix Security, EuroSP) and machine learning (NeurIPS, ICLR, ICML, CVPR, ECCV). Three following books are used for presenting background topics in machine learning and deep learning in
the first part of the course.

-   [Christopher M. Bishop, *Pattern Recognition and Machine Learning*,
    Springer,
    2006.](http://users.isr.ist.utl.pt/~wurmd/Livros/school/Bishop%20-%20Pattern%20Recognition%20And%20Machine%20Learning%20-%20Springer%20%202006.pdf)

-   [Ian Goodfellow, *Deep Learning*, MIT Press,
    2016.](https://www.deeplearningbook.org/)

-   [Aston Zhang, Dive into Deep Learning, 2020 ](http://d2l.ai/)



**Grading Policy**

Assignments (30%), Mid-term (and Mini-exam) (20%), Papers review and presentation(20%), and Final (30%).



**Course Policy**

-   This course considers topics involving personal and public privacy
    and security. As part of this investigation we will cover
    technologies whose abuse may infringe on the rights of others. As an
    instructor, I rely on the ethical use of these technologies.
    Unethical use may include circumvention of existing security or
    privacy measurements for any purpose, or the dissemination,
    promotion, or exploitation of vulnerabilities of these services.
    Exceptions to these guidelines may occur in the process of reporting
    vulnerabilities through public and authoritative channels. Any
    activity outside the letter or spirit of these guidelines will be
    reported to the proper authorities and may result in dismissal from
    the class. When in doubt, please contact the instructor for advice. **Do not**
    undertake any action which could be perceived as technology misuse
    anywhere and/or under any circumstances unless you have received
    explicit permission from Dr. Sadeghzadeh.



**Academic Honesty** 

[Sharif CE Department Honor Code](https://wiki.ce.sharif.edu/%D8%A2%DB%8C%DB%8C%D9%86_%D9%86%D8%A7%D9%85%D9%87/%D8%A2%D8%AF%D8%A7%D8%A8_%D9%86%D8%A7%D9%85%D9%87_%D8%A7%D9%86%D8%AC%D8%A7%D9%85_%D8%AA%D9%85%D8%B1%DB%8C%D9%86_%D9%87%D8%A7%DB%8C_%D8%AF%D8%B1%D8%B3%DB%8C) (please read it carefully!)



**Homework Submission**

Submit your answers in .pdf or .zip file in course page on Quera website, with the following format:
HW[HW#]-[FamilyName]-[std#] (For example HW3-Hoseini-401234567)



**Late Policy**

* All students have 14 free late days for the assignments.
* You may use up to 5 late days per assignment with no penalty.
* Once you have exhausted your free late days, we will deduct a late penalty of 20% per additional late day.


&nbsp;&nbsp;&nbsp;

&nbsp;&nbsp;&nbsp;


| # | Date  | Topic             | Content                                    | Lecture | Reading                                                                                                                                                                                                                                                                               | HWs |
|---|-------|-------------------|--------------------------------------------|---------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|-----|
| 1 | 7/1 | Course Intro.     | The scope and contents of the course       | [Lec1](https://github.com/spml2024/spml2024.github.io/raw/main/Lectures/Lec1.pdf)    | [Towards the Science of Security and Privacy in Machine Learning](https://arxiv.org/abs/1611.03814)                                                                                                                                                                           |     |
| 2 | 7/3 | Deep Learning Review     | ML Intro., Perceptron, Logistic regression, GD, Regularization       | [Lec2](https://github.com/spml2024/spml2024.github.io/raw/main/Lectures/Lec2.pdf)    | [Pattern Recognition and Machine Learning Ch.1 & Ch.4](http://users.isr.ist.utl.pt/~wurmd/Livros/school/Bishop\%20-\%20Pattern\%20Recognition\%20And\%20Machine\%20Learning\%20-\%20Springer\%20\%202006.pdf) <br> [Deep Learning Ch.5 & Ch.6](https://www.deeplearningbook.org/)                                                                                                                                                                          |     |
| 3 | 7/8 | Deep Learning Review     |   Softmax Classifier, Neural networks          | [Lec3](https://github.com/spml2024/spml2024.github.io/raw/main/Lectures/Lec3.pdf)    |  [Deep Learning Ch.6, ch.8 & Ch.9](https://www.deeplearningbook.org/)  <br> [The Neural Network, A Visual Introduction](https://www.youtube.com/watch?v=UOvPeC8WOt8&t=20s) <br> [Why are neural networks so effective?](https://www.youtube.com/watch?v=-at7SLoVK_I&t=732s)                                                                                                                                                                         |     |
| 4 | 7/10 | Deep Learning Review     | Forward and backward propagation, Convolutional Neural Networks (CNNs)         | [Lec4](https://github.com/spml2024/spml2024.github.io/raw/main/Lectures/Lec4.pdf)    | [Deep Learning Ch.6 & ch.9](https://www.deeplearningbook.org/)   <br> [Dive into Deep Learning Ch. 8](http://d2l.ai/) <br> [Backpropagation for a Linear Layer](https://web.eecs.umich.edu/~justincj/teaching/eecs442/notes/linear-backprop.html)    <br> [What is backpropagation really doing?](https://www.youtube.com/playlist?list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi)                                                                                                                                                                         |     |
| 5 | 7/15  | Adversarial Examples             | AE Generating Methods                      | [Lec5](https://github.com/spml2024/spml2024.github.io/raw/main/Lectures/Lec5.pdf)   | [Intriguing Properties of Neural Networks](https://arxiv.org/abs/1312.6199) |     |
| 6 | 7/17  | Adversarial Examples             | AE Generating Methods                              | [Lec6](https://github.com/spml2024/spml2024.github.io/raw/main/Lectures/Lec6.pdf)   |  [Explaining and Harnessing Adversarial Examples](https://arxiv.org/abs/1412.6572)                  |     |
| 7 | 7/22 | Adversarial Examples             |      AE Generating Methods                  | [Lec7](https://github.com/spml2024/spml2024.github.io/raw/main/Lectures/Lec7.pdf)   |   [Towards Evaluating the Robustness of Neural Networks](https://arxiv.org/abs/1608.04644)                                                           |    |
| 8 | 7/24 | Adversarial Examples             |      AE Generating Methods                  | [Lec8](https://github.com/spml2024/spml2024.github.io/raw/main/Lectures/Lec8.pdf)   |   [Universal Adversarial Perturbations](https://arxiv.org/abs/1610.08401) <br> [Adversarial Patch](https://arxiv.org/abs/1712.09665)                                                             |    |
| 9 | 8/29 | Adversarial Examples             |      Defenses Against AEs                 | [Lec9](https://github.com/spml2024/spml2024.github.io/raw/main/Lectures/Lec9.pdf)   |    [Towards Deep Learning Models Resistant to Adversarial Attacks](https://arxiv.org/abs/1706.06083) <br> [Obfuscated Gradients Give a False Sense of Security: Circumventing Defenses to Adversarial Examples](http://proceedings.mlr.press/v80/athalye18a/athalye18a.pdf)                                                               |    |
| 10 | 8/1 |           |                    |   |                                                            |    | 
| 11 | 8/6 | Adversarial Examples             |      Defenses Against AEs             | [Lec10](https://github.com/spml2024/spml2024.github.io/raw/main/Lectures/Lec10.pdf)   |  [Certified Adversarial Robustness via Randomized Smoothing](https://arxiv.org/pdf/1902.02918) <br> [Provably robust deep learning via adversarially trained smoothed classifiers](https://proceedings.neurips.cc/paper/2019/file/3a24b25a7b092a252166a1641ae953e7-Paper.pdf)                                                            |    |
| 12 | 8/8 | Adversarial Examples             |      Defenses Against AEs                  | [Lec11](https://github.com/spml2024/spml2024.github.io/raw/main/Lectures/Lec11.pdf)   |   [Certified Adversarial Robustness via Randomized Smoothing](https://arxiv.org/pdf/1902.02918) <br> [Provably robust deep learning via adversarially trained smoothed classifiers](https://proceedings.neurips.cc/paper/2019/file/3a24b25a7b092a252166a1641ae953e7-Paper.pdf) <br> [Practical Black-Box Attacks against Machine Learning](https://www.cs.purdue.edu/homes/bb/2020-fall-cs590bb/docs/at/attacks-against-machine-learning.pdf)                                                          |    |
| 13 | 8/13   |      Adversarial Examples             |       Black-box AEs                                     |   [Lec12](https://github.com/spml2024/spml2024.github.io/raw/main/Lectures/Lec12.pdf)      |      [ZOO: Zeroth Order Optimization Based Black-box Attacks to Deep Neural Networks without Training Substitute Models](https://dl.acm.org/doi/pdf/10.1145/3128572.3140448)  <br> [Black-box Adversarial Attacks with Limited Queries and Information](https://arxiv.org/pdf/1804.08598)  | |
| 14 | 8/15   |      Adversarial Examples             |       Black-box AEs   - Data Poisoning                                 |   [Lec13](https://github.com/spml2024/spml2024.github.io/raw/main/Lectures/Lec13.pdf)    |    [Black-box Adversarial Attacks with Limited Queries and Information](https://arxiv.org/pdf/1804.08598) <br> [BadNets: Identifying Vulnerabilities in the Machine Learning Model Supply Chain](https://arxiv.org/abs/1708.06733)  <br> [Clean-Label Backdoor Attacks](https://people.csail.mit.edu/madry/lab/cleanlabel.pdf)   |  |
| 15 | 8/20  | Poisoning                        | Poisoning                                  |  [Lec14](https://github.com/spml2024/spml2024.github.io/raw/main/Lectures/Lec14.pdf)  | [Poison Frogs! Targeted Clean-Label Poisoning Attacks on Neural Networks](https://arxiv.org/abs/1804.00792) <br> [Deep Partition Aggregation: Provable Defense against General Poisoning Attacks](https://arxiv.org/pdf/2006.14768)  ||
| 16 | 8/22  | Model Extraction                 | ME Attacks                                 | [Lec15](https://github.com/spml2024/spml2024.github.io/raw/main/Lectures/Lec15.pdf)    | [High Accuracy and High Fidelity Extraction of Neural Networks](https://arxiv.org/abs/1909.01838)  <br> [Knockoff Nets: Stealing Functionality of Black-Box Models](https://arxiv.org/abs/1812.02766) |     |
| 17 | 8/27  | Model Extraction   - Privacy              | ME Defenses - Privacy Risks                              | [Lec16](https://github.com/spml2024/spml2024.github.io/raw/main/Lectures/Lec16.pdf)    |  [Turning Your Weakness Into a Strength: Watermarking Deep Neural Networks by Backdooring](https://arxiv.org/pdf/1802.04633)                     |     |                                                                                                       
| 18 | 8/29  | Privacy                          | Privacy Risks                       | [Lec17](https://github.com/spml2024/spml2024.github.io/raw/main/Lectures/Lec17.pdf)    | [Membership Inference Attacks against Machine Learning Models](https://arxiv.org/abs/1610.05820)                                                                                                                    |    |
| 19 | 9/4   | Presentation                     |            Student presentation                                |        |     |     |
| 20 | 9/6   | Presentation                     |            Student presentation                                |        |     |     |
| 21 | 9/11   | Presentation                     |            Student presentation                                |        |     |     |
| 22 | 9/13  | Privacy                          | Differential Privacy                       | [Lec18](https://github.com/spml2024/spml2024.github.io/raw/main/Lectures/Lec18.pdf)   |  [Passive and Active White-box Inference Attacks against Centralized and Federated Learning](https://arxiv.org/abs/1812.00910)                                                                                                                                                                                                                                                        |     |
| 23 | 9/18   | Privacy                          | Privacy-preserving DL                      | [Lec19](https://github.com/spml2024/spml2024.github.io/raw/main/Lectures/Lec19.pdf)   |  [The Algorithmic Foundations of Differential Privacy](https://www.cis.upenn.edu/~aaroth/Papers/privacybook.pdf)                                                                                                                                                                                                       |     |                                                                                                                         |     |
| 24 | 9/20   | Privacy                          | Privacy-preserving DL                      | [Lec20](https://github.com/spml2024/spml2024.github.io/raw/main/Lectures/Lec20.pdf)   | [The Algorithmic Foundations of Differential Privacy](https://www.cis.upenn.edu/~aaroth/Papers/privacybook.pdf)  <br> [Deep Learning with Differential Privacy](https://arxiv.org/abs/1607.00133)                                                                                                                                                                                                  |     |                                                                                                                         |     |
| 25 | 9/27   | Privacy                          | Privacy-preserving DL                      | [Lec20](https://github.com/spml2024/spml2024.github.io/raw/main/Lectures/Lec20.pdf)   | [The Algorithmic Foundations of Differential Privacy](https://www.cis.upenn.edu/~aaroth/Papers/privacybook.pdf)  <br> [Deep Learning with Differential Privacy](https://arxiv.org/abs/1607.00133) <br> [Semi-supervised Knowledge Transfer for Deep Learning from Private Training Data](https://arxiv.org/abs/1610.05755)                                                                                                                                                                                                       |     |                                                                                                                         |     |
| 26 | 10/2   | Generative models security                         |                     |   [Lec21](https://github.com/spml2024/spml2024.github.io/raw/main/Lectures/Lec21.pdf) |                                                                                                                                                                                                        |     |                                                                                                                         |     |
| 27 | 10/4   | Generative models security                           |                     | [Lec22](https://github.com/spml2024/spml2024.github.io/raw/main/Lectures/Lec22.pdf)  |                                                                                                                                                                                                      |     |                                                                                                                         |     |
| 26 | 10/2   | Generative models security                         |                     | [Lec23](https://github.com/spml2024/spml2024.github.io/raw/main/Lectures/Lec23.pdf)   |                                                                                                                                                                                                        |     |                                                                                                                         |     |

